{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e3b6e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "from contextlib import contextmanager\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import lightgbm as lgb\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optuna\n",
    "from scipy.stats import ks_2samp\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from boruta import BorutaPy\n",
    "# import optuna.integration.lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66581acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc980709",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_final.csv')\n",
    "test=pd.read_csv('test_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "167f5d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id=pd.read_csv('test_final.csv')['card_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abd443e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96f50905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# Fix datetime columns to be relative floating points\n",
    "\n",
    "object_cols = train_df.select_dtypes(include=['O']).columns\n",
    "ref = datetime(2017, 1, 1)\n",
    "\n",
    "for col in object_cols:\n",
    "    if 'latest' in col or 'earliest' in col:\n",
    "        train_df[col] = (pd.to_datetime(train_df[col]) - ref).dt.total_seconds() / 3600.0\n",
    "\n",
    "for col in object_cols:\n",
    "    if 'latest' in col or 'earliest' in col:\n",
    "        test[col] = (pd.to_datetime(test[col]) - ref).dt.total_seconds() / 3600.0\n",
    "# Remove remaining features of type Object\n",
    "\n",
    "train_df = train_df.drop(columns=train_df.select_dtypes(include=['O']).columns)\n",
    "test = test.drop(columns=test.select_dtypes(include=['O']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf15b40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "      <th>new_flag_mean</th>\n",
       "      <th>new_flag_median</th>\n",
       "      <th>new_flag_sum</th>\n",
       "      <th>new_flag_sum0</th>\n",
       "      <th>new_flag_mode</th>\n",
       "      <th>new_flag_std</th>\n",
       "      <th>...</th>\n",
       "      <th>transaction_frequency_c3_NA_1</th>\n",
       "      <th>count_c3_NA_0</th>\n",
       "      <th>latest_transaction_c3_NA_0</th>\n",
       "      <th>earliest_transaction_c3_NA_0</th>\n",
       "      <th>days_active_c3_NA_0</th>\n",
       "      <th>transaction_frequency_c3_NA_0</th>\n",
       "      <th>city_max_spent</th>\n",
       "      <th>merchant_category_max_spent</th>\n",
       "      <th>state_max_spent</th>\n",
       "      <th>subsector_max_spent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.820283</td>\n",
       "      <td>0.083032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>254</td>\n",
       "      <td>False</td>\n",
       "      <td>0.276431</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277</td>\n",
       "      <td>11603.384722</td>\n",
       "      <td>4262.302222</td>\n",
       "      <td>305</td>\n",
       "      <td>0.908197</td>\n",
       "      <td>69</td>\n",
       "      <td>560</td>\n",
       "      <td>9</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>350</td>\n",
       "      <td>False</td>\n",
       "      <td>0.128905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>354</td>\n",
       "      <td>10878.807222</td>\n",
       "      <td>136.495000</td>\n",
       "      <td>447</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>69</td>\n",
       "      <td>307</td>\n",
       "      <td>9</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>False</td>\n",
       "      <td>0.150756</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>11585.719722</td>\n",
       "      <td>248.356111</td>\n",
       "      <td>472</td>\n",
       "      <td>0.093220</td>\n",
       "      <td>143</td>\n",
       "      <td>705</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>77</td>\n",
       "      <td>False</td>\n",
       "      <td>0.278045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>81</td>\n",
       "      <td>11339.003056</td>\n",
       "      <td>6448.372500</td>\n",
       "      <td>203</td>\n",
       "      <td>0.399015</td>\n",
       "      <td>17</td>\n",
       "      <td>278</td>\n",
       "      <td>22</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159749</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>132</td>\n",
       "      <td>False</td>\n",
       "      <td>0.411553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>167</td>\n",
       "      <td>11586.840278</td>\n",
       "      <td>7560.000000</td>\n",
       "      <td>167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>278</td>\n",
       "      <td>22</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2815 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3    target  new_flag_mean  new_flag_median  \\\n",
       "0          5          2          1 -0.820283       0.083032              0.0   \n",
       "1          4          1          0  0.392913       0.016854              0.0   \n",
       "2          2          2          0  0.688056       0.022727              0.0   \n",
       "3          4          3          0  0.142495       0.083333              0.0   \n",
       "4          1          3          0 -0.159749       0.214286              0.0   \n",
       "\n",
       "   new_flag_sum  new_flag_sum0  new_flag_mode  new_flag_std  ...  \\\n",
       "0            23            254          False      0.276431  ...   \n",
       "1             6            350          False      0.128905  ...   \n",
       "2             1             43          False      0.150756  ...   \n",
       "3             7             77          False      0.278045  ...   \n",
       "4            36            132          False      0.411553  ...   \n",
       "\n",
       "   transaction_frequency_c3_NA_1  count_c3_NA_0  latest_transaction_c3_NA_0  \\\n",
       "0                            NaN            277                11603.384722   \n",
       "1                       0.086957            354                10878.807222   \n",
       "2                            NaN             44                11585.719722   \n",
       "3                       0.021277             81                11339.003056   \n",
       "4                       0.000000            167                11586.840278   \n",
       "\n",
       "   earliest_transaction_c3_NA_0  days_active_c3_NA_0  \\\n",
       "0                   4262.302222                  305   \n",
       "1                    136.495000                  447   \n",
       "2                    248.356111                  472   \n",
       "3                   6448.372500                  203   \n",
       "4                   7560.000000                  167   \n",
       "\n",
       "   transaction_frequency_c3_NA_0  city_max_spent  merchant_category_max_spent  \\\n",
       "0                       0.908197              69                          560   \n",
       "1                       0.791946              69                          307   \n",
       "2                       0.093220             143                          705   \n",
       "3                       0.399015              17                          278   \n",
       "4                       1.000000              17                          278   \n",
       "\n",
       "   state_max_spent  subsector_max_spent  \n",
       "0                9                   34  \n",
       "1                9                   34  \n",
       "2                5                   33  \n",
       "3               22                   37  \n",
       "4               22                   37  \n",
       "\n",
       "[5 rows x 2815 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bea3040",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "\n",
    "# rmse\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# One-hot encoding for categorical columns with get_dummies\n",
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns\n",
    "    \n",
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb0cb428",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_columns = train_df.select_dtypes(include=['object']).columns\n",
    "date_columns = train_df.select_dtypes(include=['datetime64[ns]']).columns\n",
    "train_df.drop(string_columns.union(date_columns), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d07a8e",
   "metadata": {},
   "source": [
    "# Only keep features with na_ratio<0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "270cb547",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_ratio = train_df.isna().mean()\n",
    "\n",
    "# Drop columns where the ratio of NA is greater than 0.5\n",
    "train_df = train_df.loc[:, na_ratio <= 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1178d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [fea for fea in train_df.columns if fea != \"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71155c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy import stats\n",
    "# # Calculate the Z-scores of all columns\n",
    "# z_scores = stats.zscore(train_df[feats])\n",
    "\n",
    "# # Get absolute Z-scores\n",
    "# abs_z_scores = np.abs(z_scores)\n",
    "\n",
    "# # Find rows where all the Z-scores are less than the threshold\n",
    "# filtered_entries = (abs_z_scores <= 5).all(axis=1)\n",
    "\n",
    "# # Select only the valid entries\n",
    "# train_df = train_df[filtered_entries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "978b6ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201917"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0c13dc",
   "metadata": {},
   "source": [
    "# Remove features stepwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d88cae8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 4.637589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 279111\n",
      "[LightGBM] [Info] Number of data points in the train set: 201917, number of used features: 1875\n",
      "[LightGBM] [Info] Start training from score -0.393636\n",
      "Complete one round!\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 3.412014 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 236884\n",
      "[LightGBM] [Info] Number of data points in the train set: 201917, number of used features: 1499\n",
      "[LightGBM] [Info] Start training from score -0.393636\n",
      "Complete one round!\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.188220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 199888\n",
      "[LightGBM] [Info] Number of data points in the train set: 201917, number of used features: 1200\n",
      "[LightGBM] [Info] Start training from score -0.393636\n",
      "Complete one round!\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.699920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 173953\n",
      "[LightGBM] [Info] Number of data points in the train set: 201917, number of used features: 1000\n",
      "[LightGBM] [Info] Start training from score -0.393636\n",
      "Complete one round!\n"
     ]
    }
   ],
   "source": [
    "feature_reduction_stages = [1500, 1200, 1000, 800]\n",
    "\n",
    "for target_feature_count in feature_reduction_stages:\n",
    "    while len(train_df.drop(columns='target').columns) > target_feature_count+1:\n",
    "        # Train LightGBM model\n",
    "        model = lgb.LGBMRegressor(metric= 'rmse',learning_rate= 0.05)\n",
    "        model.fit(train_df.drop(columns='target'), train_df['target'])\n",
    "\n",
    "        # Get feature importances and sort them\n",
    "        importances = pd.Series(model.feature_importances_, index=train_df.drop(columns='target').columns)\n",
    "        sorted_features = importances.sort_values(ascending=True)\n",
    "\n",
    "        # Drop the least important features\n",
    "        features_to_drop = sorted_features.head(len(train_df.drop(columns='target').columns) - target_feature_count).index\n",
    "        train_df.drop(columns=features_to_drop, inplace=True)\n",
    "#         X_test.drop(columns=features_to_drop, inplace=True)\n",
    "\n",
    "    print(\"Complete one round!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e209246e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc309f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.484079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150202\n",
      "[LightGBM] [Info] Number of data points in the train set: 201917, number of used features: 800\n",
      "[LightGBM] [Info] Start training from score -0.393636\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lgb.LGBMRegressor()\n",
    "model.fit(train_df.drop(columns='target'), train_df['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562a6240",
   "metadata": {},
   "source": [
    "# Drop rows with z score>5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a872f459",
   "metadata": {},
   "source": [
    "It can only based on the top20 features because too many data will ruin the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffa11858",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.Series(model.feature_importances_, index=train_df.drop(columns='target').columns)\n",
    "sorted_features = importances.sort_values(ascending=True)\n",
    "\n",
    "# Drop the least important features\n",
    "features_top20 = sorted_features.tail(20).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa384159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "# Calculate the Z-scores of all columns\n",
    "# z_scores = stats.zscore(train_df[features_top20])\n",
    "df_zscore = train_df[features_top20].apply(lambda x: zscore(x, nan_policy='omit'))\n",
    "# Get absolute Z-scores\n",
    "abs_z_scores = np.abs(df_zscore)\n",
    "\n",
    "# Find rows where all the Z-scores are less than the threshold\n",
    "filtered_entries = ((abs_z_scores <= 10) | (pd.isna(abs_z_scores))).all(axis=1)\n",
    "\n",
    "# Select only the valid entries\n",
    "train_df = train_df[filtered_entries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9018ff4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29e32bb9",
   "metadata": {},
   "source": [
    "# Transform train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ab01105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test=pd.read_csv('test_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2a4390ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_ele=train_df.drop(columns=['target']).columns.tolist()\n",
    "# all_ele.append('card_id')\n",
    "\n",
    "ytrain=train_df['target']\n",
    "xtrain=train_df.drop(columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "66139aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest=test[train_df.drop(columns=['target']).columns.tolist()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4667b377",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain['feature_3']=data['feature_3']\n",
    "xtest['feature_3']=test['feature_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "364c7858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_1\n",
      "feature_2\n",
      "feature_3\n"
     ]
    }
   ],
   "source": [
    "categorical_feats = ['feature_1', 'feature_2', 'feature_3']\n",
    "\n",
    "for col in categorical_feats:\n",
    "    print(col)\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(xtrain[col].values.astype('str')) + list(xtest[col].values.astype('str')))\n",
    "    xtrain[col] = lbl.transform(list(xtrain[col].values.astype('str')))\n",
    "    xtest[col] = lbl.transform(list(xtest[col].values.astype('str')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "83e2d950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([xtrain, xtest])\n",
    "df_all = pd.get_dummies(df_all, columns=categorical_feats)\n",
    "\n",
    "len_train = xtrain.shape[0]\n",
    "\n",
    "xtrain = df_all[:len_train]\n",
    "xtest = df_all[len_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d78f9d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for modeling\n",
    "# id_train = xtrain['card_id'].copy()\n",
    "# xtrain.drop('card_id', axis = 1, inplace = True)\n",
    "# id_test = xtest['card_id'].copy()\n",
    "# xtest.drop('card_id', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c49f39",
   "metadata": {},
   "source": [
    "# Use optuna for choosing params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2bc10f12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 20:02:25,618] A new study created in memory with name: no-name-1fe3fd42-b00e-4592-8c84-4572825ca141\n",
      "[I 2023-12-04 20:03:01,453] Trial 0 finished with value: 3.7402987846976603 and parameters: {'lambda_l1': 0.014482608322364938, 'lambda_l2': 1.4687639055370897e-07, 'num_leaves': 95, 'feature_fraction': 0.5664443993970065, 'bagging_fraction': 0.6814234346626591, 'bagging_freq': 7, 'min_child_samples': 85, 'learning_rate': 0.04518047205173545}. Best is trial 0 with value: 3.7402987846976603.\n",
      "[I 2023-12-04 20:03:29,721] Trial 1 finished with value: 3.6566559812388726 and parameters: {'lambda_l1': 6.951427779648484e-08, 'lambda_l2': 6.332153527475398e-08, 'num_leaves': 91, 'feature_fraction': 0.42228588141923534, 'bagging_fraction': 0.7044968326422897, 'bagging_freq': 3, 'min_child_samples': 25, 'learning_rate': 0.030557715251669917}. Best is trial 1 with value: 3.6566559812388726.\n",
      "[I 2023-12-04 20:04:04,701] Trial 2 finished with value: 3.6406438887729515 and parameters: {'lambda_l1': 6.406334515636689, 'lambda_l2': 3.155298400434068e-08, 'num_leaves': 81, 'feature_fraction': 0.5737144119724871, 'bagging_fraction': 0.9845570507670207, 'bagging_freq': 4, 'min_child_samples': 89, 'learning_rate': 0.016639032655347084}. Best is trial 2 with value: 3.6406438887729515.\n",
      "[I 2023-12-04 20:04:45,720] Trial 3 finished with value: 3.6353178475131758 and parameters: {'lambda_l1': 4.2222539261509103e-07, 'lambda_l2': 2.479492091367413e-07, 'num_leaves': 108, 'feature_fraction': 0.9643702044075495, 'bagging_fraction': 0.7013738643209152, 'bagging_freq': 3, 'min_child_samples': 10, 'learning_rate': 0.022342936085316335}. Best is trial 3 with value: 3.6353178475131758.\n",
      "[I 2023-12-04 20:05:17,380] Trial 4 finished with value: 3.723774119591962 and parameters: {'lambda_l1': 0.5948565794081124, 'lambda_l2': 0.06000714016337222, 'num_leaves': 149, 'feature_fraction': 0.420745202809071, 'bagging_fraction': 0.4787053595233701, 'bagging_freq': 5, 'min_child_samples': 12, 'learning_rate': 0.054695309649962325}. Best is trial 3 with value: 3.6353178475131758.\n",
      "[I 2023-12-04 20:06:03,098] Trial 5 finished with value: 3.5996662426793193 and parameters: {'lambda_l1': 4.268884174121544, 'lambda_l2': 3.4986949925281417e-06, 'num_leaves': 177, 'feature_fraction': 0.6913332352383577, 'bagging_fraction': 0.8455817505686081, 'bagging_freq': 5, 'min_child_samples': 9, 'learning_rate': 0.05444771659431233}. Best is trial 5 with value: 3.5996662426793193.\n",
      "[I 2023-12-04 20:06:44,287] Trial 6 finished with value: 3.7224681254220133 and parameters: {'lambda_l1': 0.0008468053499948582, 'lambda_l2': 0.2291271875778238, 'num_leaves': 166, 'feature_fraction': 0.6139028225404508, 'bagging_fraction': 0.6019948427385762, 'bagging_freq': 3, 'min_child_samples': 23, 'learning_rate': 0.08357883268823983}. Best is trial 5 with value: 3.5996662426793193.\n",
      "[I 2023-12-04 20:07:13,567] Trial 7 finished with value: 3.7416105112742173 and parameters: {'lambda_l1': 5.609971641721765, 'lambda_l2': 0.16421073554389687, 'num_leaves': 33, 'feature_fraction': 0.46716600367802463, 'bagging_fraction': 0.8381988877191968, 'bagging_freq': 4, 'min_child_samples': 29, 'learning_rate': 0.09213894652257827}. Best is trial 5 with value: 3.5996662426793193.\n",
      "[I 2023-12-04 20:07:49,389] Trial 8 finished with value: 3.6314709430616343 and parameters: {'lambda_l1': 1.7253406325114187e-07, 'lambda_l2': 0.005480736509559824, 'num_leaves': 55, 'feature_fraction': 0.8071650893010056, 'bagging_fraction': 0.8751167854518118, 'bagging_freq': 1, 'min_child_samples': 71, 'learning_rate': 0.07766903657495827}. Best is trial 5 with value: 3.5996662426793193.\n",
      "[I 2023-12-04 20:08:17,404] Trial 9 finished with value: 3.6534407547339622 and parameters: {'lambda_l1': 0.00043819602088855956, 'lambda_l2': 1.1445713427913889e-07, 'num_leaves': 60, 'feature_fraction': 0.6181678502558419, 'bagging_fraction': 0.6610627007722991, 'bagging_freq': 6, 'min_child_samples': 35, 'learning_rate': 0.05977848033633193}. Best is trial 5 with value: 3.5996662426793193.\n",
      "[I 2023-12-04 20:09:20,331] Trial 10 finished with value: 3.6737763475062857 and parameters: {'lambda_l1': 0.05034451812622931, 'lambda_l2': 2.0065760673497103e-05, 'num_leaves': 248, 'feature_fraction': 0.7420406904812714, 'bagging_fraction': 0.8284700065180726, 'bagging_freq': 1, 'min_child_samples': 52, 'learning_rate': 0.0027326859632050837}. Best is trial 5 with value: 3.5996662426793193.\n",
      "[I 2023-12-04 20:10:14,331] Trial 11 finished with value: 3.8247727305551242 and parameters: {'lambda_l1': 3.84297536715283e-06, 'lambda_l2': 0.0007047064725965739, 'num_leaves': 187, 'feature_fraction': 0.7806786574889208, 'bagging_fraction': 0.9099899771680626, 'bagging_freq': 1, 'min_child_samples': 69, 'learning_rate': 0.07380313569022114}. Best is trial 5 with value: 3.5996662426793193.\n",
      "[I 2023-12-04 20:11:12,985] Trial 12 finished with value: 3.6882296615514196 and parameters: {'lambda_l1': 4.721134333191936e-06, 'lambda_l2': 0.0005303157669805266, 'num_leaves': 214, 'feature_fraction': 0.8172003296728464, 'bagging_fraction': 0.8290508420271484, 'bagging_freq': 6, 'min_child_samples': 58, 'learning_rate': 0.07133646443237888}. Best is trial 5 with value: 3.5996662426793193.\n",
      "[I 2023-12-04 20:11:36,263] Trial 13 finished with value: 3.6653653718914407 and parameters: {'lambda_l1': 1.0370565166762518e-08, 'lambda_l2': 1.8157543239161875e-05, 'num_leaves': 4, 'feature_fraction': 0.8573388073656877, 'bagging_fraction': 0.9760786073174899, 'bagging_freq': 2, 'min_child_samples': 72, 'learning_rate': 0.09821182938339172}. Best is trial 5 with value: 3.5996662426793193.\n",
      "[I 2023-12-04 20:12:21,159] Trial 14 finished with value: 3.671979175100811 and parameters: {'lambda_l1': 1.9760928795992608e-05, 'lambda_l2': 5.98868873753135, 'num_leaves': 144, 'feature_fraction': 0.7196651848028782, 'bagging_fraction': 0.8799340918193252, 'bagging_freq': 5, 'min_child_samples': 44, 'learning_rate': 0.06797079239003324}. Best is trial 5 with value: 3.5996662426793193.\n",
      "[I 2023-12-04 20:13:11,084] Trial 15 finished with value: 3.641830591070138 and parameters: {'lambda_l1': 6.115233377975973e-05, 'lambda_l2': 7.497831960640216e-06, 'num_leaves': 193, 'feature_fraction': 0.6834154526606868, 'bagging_fraction': 0.785611082055991, 'bagging_freq': 2, 'min_child_samples': 71, 'learning_rate': 0.044116697944562626}. Best is trial 5 with value: 3.5996662426793193.\n",
      "[I 2023-12-04 20:13:43,949] Trial 16 finished with value: 3.66243154026896 and parameters: {'lambda_l1': 0.006470864159287875, 'lambda_l2': 0.004669377673205608, 'num_leaves': 47, 'feature_fraction': 0.857531820646315, 'bagging_fraction': 0.9170353941110448, 'bagging_freq': 5, 'min_child_samples': 97, 'learning_rate': 0.08320932286153682}. Best is trial 5 with value: 3.5996662426793193.\n",
      "[I 2023-12-04 20:14:58,108] Trial 17 finished with value: 3.629484287904483 and parameters: {'lambda_l1': 0.14757564078188284, 'lambda_l2': 8.350468283487465e-05, 'num_leaves': 250, 'feature_fraction': 0.9470815113407761, 'bagging_fraction': 0.913262694911692, 'bagging_freq': 7, 'min_child_samples': 61, 'learning_rate': 0.05456901747335659}. Best is trial 5 with value: 3.5996662426793193.\n",
      "[I 2023-12-04 20:16:11,252] Trial 18 finished with value: 3.637273884315396 and parameters: {'lambda_l1': 0.15194012117645853, 'lambda_l2': 1.1787531186349664e-06, 'num_leaves': 256, 'feature_fraction': 0.9716173353247305, 'bagging_fraction': 0.766044308177941, 'bagging_freq': 7, 'min_child_samples': 43, 'learning_rate': 0.06294367039486017}. Best is trial 5 with value: 3.5996662426793193.\n",
      "[I 2023-12-04 20:17:12,611] Trial 19 finished with value: 3.7288425604158317 and parameters: {'lambda_l1': 0.4552351606582672, 'lambda_l2': 4.3358600060606897e-05, 'num_leaves': 228, 'feature_fraction': 0.9293743079712278, 'bagging_fraction': 0.9447990423125433, 'bagging_freq': 6, 'min_child_samples': 5, 'learning_rate': 0.05382836743833932}. Best is trial 5 with value: 3.5996662426793193.\n",
      "[I 2023-12-04 20:18:07,745] Trial 20 finished with value: 3.6335572764316186 and parameters: {'lambda_l1': 1.6230398571119493, 'lambda_l2': 2.8824373035677065e-06, 'num_leaves': 213, 'feature_fraction': 0.6804261042876101, 'bagging_fraction': 0.9942717051579247, 'bagging_freq': 7, 'min_child_samples': 57, 'learning_rate': 0.041066746559860895}. Best is trial 5 with value: 3.5996662426793193.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 20:18:55,510] Trial 21 finished with value: 3.6532013144543254 and parameters: {'lambda_l1': 9.752599366270442, 'lambda_l2': 0.0001488370021664347, 'num_leaves': 121, 'feature_fraction': 0.9037676917284035, 'bagging_fraction': 0.8895788757114175, 'bagging_freq': 6, 'min_child_samples': 66, 'learning_rate': 0.06310830088982684}. Best is trial 5 with value: 3.5996662426793193.\n",
      "[I 2023-12-04 20:19:49,173] Trial 22 finished with value: 3.654223577663399 and parameters: {'lambda_l1': 0.07848628741332174, 'lambda_l2': 0.00012585922636568493, 'num_leaves': 176, 'feature_fraction': 0.78481702789697, 'bagging_fraction': 0.8741525374075746, 'bagging_freq': 2, 'min_child_samples': 80, 'learning_rate': 0.05241006478937153}. Best is trial 5 with value: 3.5996662426793193.\n",
      "[I 2023-12-04 20:20:40,159] Trial 23 finished with value: 3.542113849338635 and parameters: {'lambda_l1': 0.009378943867781906, 'lambda_l2': 1.6036090134055939e-06, 'num_leaves': 144, 'feature_fraction': 0.8952864576742605, 'bagging_fraction': 0.9284567661492465, 'bagging_freq': 5, 'min_child_samples': 49, 'learning_rate': 0.07958940675014119}. Best is trial 23 with value: 3.542113849338635.\n",
      "[I 2023-12-04 20:21:37,276] Trial 24 finished with value: 3.8026379698498385 and parameters: {'lambda_l1': 0.004599073012860207, 'lambda_l2': 1.3786389164229828e-06, 'num_leaves': 156, 'feature_fraction': 0.995296283451967, 'bagging_fraction': 0.923554501887508, 'bagging_freq': 5, 'min_child_samples': 47, 'learning_rate': 0.06671281150250373}. Best is trial 23 with value: 3.542113849338635.\n",
      "[I 2023-12-04 20:22:39,350] Trial 25 finished with value: 3.6735789657768905 and parameters: {'lambda_l1': 0.7892636030326534, 'lambda_l2': 1.183568823507847e-08, 'num_leaves': 202, 'feature_fraction': 0.8955811965146261, 'bagging_fraction': 0.9702101491199309, 'bagging_freq': 4, 'min_child_samples': 35, 'learning_rate': 0.03730731352317292}. Best is trial 23 with value: 3.542113849338635.\n",
      "[I 2023-12-04 20:23:30,098] Trial 26 finished with value: 3.5546293030186877 and parameters: {'lambda_l1': 0.02887398972785131, 'lambda_l2': 6.597687218003759e-07, 'num_leaves': 127, 'feature_fraction': 0.9304383016909369, 'bagging_fraction': 0.9469003952287367, 'bagging_freq': 6, 'min_child_samples': 59, 'learning_rate': 0.055224116201390894}. Best is trial 23 with value: 3.542113849338635.\n",
      "[I 2023-12-04 20:24:17,215] Trial 27 finished with value: 3.6669729387136427 and parameters: {'lambda_l1': 0.0017269936431555265, 'lambda_l2': 5.185129648759205e-07, 'num_leaves': 131, 'feature_fraction': 0.8635231305138215, 'bagging_fraction': 0.9489376878299453, 'bagging_freq': 5, 'min_child_samples': 35, 'learning_rate': 0.07781419744600605}. Best is trial 23 with value: 3.542113849338635.\n",
      "[I 2023-12-04 20:25:06,410] Trial 28 finished with value: 3.6556048396408514 and parameters: {'lambda_l1': 0.016796561690767417, 'lambda_l2': 5.444922654133187e-06, 'num_leaves': 125, 'feature_fraction': 0.9884882582076283, 'bagging_fraction': 0.9915667002010701, 'bagging_freq': 6, 'min_child_samples': 18, 'learning_rate': 0.060187865090446366}. Best is trial 23 with value: 3.542113849338635.\n",
      "[I 2023-12-04 20:26:05,673] Trial 29 finished with value: 3.6923755962384694 and parameters: {'lambda_l1': 0.022551429293250085, 'lambda_l2': 3.2238196251096773e-07, 'num_leaves': 168, 'feature_fraction': 0.9283480745014862, 'bagging_fraction': 0.9374505114510447, 'bagging_freq': 5, 'min_child_samples': 80, 'learning_rate': 0.041191280432534054}. Best is trial 23 with value: 3.542113849338635.\n",
      "[I 2023-12-04 20:26:46,097] Trial 30 finished with value: 3.720459783988118 and parameters: {'lambda_l1': 0.003878657698948027, 'lambda_l2': 9.9661153712365e-07, 'num_leaves': 110, 'feature_fraction': 0.7508919685165132, 'bagging_fraction': 0.8459442334408958, 'bagging_freq': 4, 'min_child_samples': 51, 'learning_rate': 0.0470386039408825}. Best is trial 23 with value: 3.542113849338635.\n",
      "[I 2023-12-04 20:27:57,920] Trial 31 finished with value: 3.681157633960027 and parameters: {'lambda_l1': 0.2507188744664128, 'lambda_l2': 4.779628933381681e-06, 'num_leaves': 235, 'feature_fraction': 0.9523198683476041, 'bagging_fraction': 0.9296191833574097, 'bagging_freq': 7, 'min_child_samples': 62, 'learning_rate': 0.056855340090396035}. Best is trial 23 with value: 3.542113849338635.\n",
      "[I 2023-12-04 20:28:40,517] Trial 32 finished with value: 3.699229508632648 and parameters: {'lambda_l1': 0.05561406080845288, 'lambda_l2': 1.5362942407457075e-07, 'num_leaves': 88, 'feature_fraction': 0.9162476265420136, 'bagging_fraction': 0.8935381648570913, 'bagging_freq': 7, 'min_child_samples': 62, 'learning_rate': 0.04913202308903984}. Best is trial 23 with value: 3.542113849338635.\n",
      "[I 2023-12-04 20:29:35,542] Trial 33 finished with value: 3.6201616958487595 and parameters: {'lambda_l1': 1.9925226056338283, 'lambda_l2': 5.256901271241587e-08, 'num_leaves': 138, 'feature_fraction': 0.9489123262096254, 'bagging_fraction': 0.9586505286518063, 'bagging_freq': 6, 'min_child_samples': 79, 'learning_rate': 0.04869254299823109}. Best is trial 23 with value: 3.542113849338635.\n",
      "[I 2023-12-04 20:30:33,950] Trial 34 finished with value: 3.617706338897908 and parameters: {'lambda_l1': 2.918212514382245, 'lambda_l2': 3.9166591796540805e-08, 'num_leaves': 138, 'feature_fraction': 0.9989399474394879, 'bagging_fraction': 0.9984544600522101, 'bagging_freq': 6, 'min_child_samples': 89, 'learning_rate': 0.03684469639040314}. Best is trial 23 with value: 3.542113849338635.\n",
      "[I 2023-12-04 20:31:25,155] Trial 35 finished with value: 3.679007880350078 and parameters: {'lambda_l1': 1.3288131953457982, 'lambda_l2': 2.4006179170793914e-08, 'num_leaves': 105, 'feature_fraction': 0.9982163986293862, 'bagging_fraction': 0.9928560356728287, 'bagging_freq': 6, 'min_child_samples': 98, 'learning_rate': 0.02539528825332982}. Best is trial 23 with value: 3.542113849338635.\n",
      "[I 2023-12-04 20:32:22,697] Trial 36 finished with value: 3.61918678629344 and parameters: {'lambda_l1': 2.8815481186469554, 'lambda_l2': 7.563897682268641e-08, 'num_leaves': 152, 'feature_fraction': 0.8989219559948176, 'bagging_fraction': 0.9998957482926387, 'bagging_freq': 5, 'min_child_samples': 93, 'learning_rate': 0.0355189497413337}. Best is trial 23 with value: 3.542113849338635.\n",
      "[I 2023-12-04 20:33:26,788] Trial 37 finished with value: 3.666655803532561 and parameters: {'lambda_l1': 0.3571412925280896, 'lambda_l2': 3.132705751603962e-07, 'num_leaves': 178, 'feature_fraction': 0.9631665994028435, 'bagging_fraction': 0.9453994505739929, 'bagging_freq': 4, 'min_child_samples': 88, 'learning_rate': 0.03476192760489643}. Best is trial 23 with value: 3.542113849338635.\n",
      "[I 2023-12-04 20:34:08,799] Trial 38 finished with value: 3.642270065230561 and parameters: {'lambda_l1': 5.359563606777846, 'lambda_l2': 1.4035932825216863e-08, 'num_leaves': 99, 'feature_fraction': 0.8812666762681012, 'bagging_fraction': 0.9675440710176643, 'bagging_freq': 5, 'min_child_samples': 19, 'learning_rate': 0.030743305657763606}. Best is trial 23 with value: 3.542113849338635.\n",
      "[I 2023-12-04 20:34:46,198] Trial 39 finished with value: 3.6292577481288704 and parameters: {'lambda_l1': 0.7751439780145525, 'lambda_l2': 4.7265251786415144e-08, 'num_leaves': 79, 'feature_fraction': 0.8439638221464987, 'bagging_fraction': 0.856427260724726, 'bagging_freq': 6, 'min_child_samples': 27, 'learning_rate': 0.04542651127775672}. Best is trial 23 with value: 3.542113849338635.\n",
      "[I 2023-12-04 20:35:32,519] Trial 40 finished with value: 3.625753081763959 and parameters: {'lambda_l1': 0.010867507767586125, 'lambda_l2': 1.5488722244563413e-07, 'num_leaves': 159, 'feature_fraction': 0.8251952614930192, 'bagging_fraction': 0.7950661732089965, 'bagging_freq': 4, 'min_child_samples': 12, 'learning_rate': 0.05650087983785443}. Best is trial 23 with value: 3.542113849338635.\n",
      "[I 2023-12-04 20:36:27,461] Trial 41 finished with value: 3.6771820579373227 and parameters: {'lambda_l1': 2.8369959901761623, 'lambda_l2': 7.898759183924509e-08, 'num_leaves': 149, 'feature_fraction': 0.8835139847213206, 'bagging_fraction': 0.9998996622806123, 'bagging_freq': 5, 'min_child_samples': 93, 'learning_rate': 0.03642677414388251}. Best is trial 23 with value: 3.542113849338635.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-04 20:37:18,324] Trial 42 finished with value: 3.603187712183367 and parameters: {'lambda_l1': 8.650310911236746, 'lambda_l2': 5.310971366791875e-07, 'num_leaves': 114, 'feature_fraction': 0.9220246634592111, 'bagging_fraction': 0.9616268064600636, 'bagging_freq': 5, 'min_child_samples': 92, 'learning_rate': 0.026076157600295503}. Best is trial 23 with value: 3.542113849338635.\n",
      "[I 2023-12-04 20:38:09,939] Trial 43 finished with value: 3.6800902165903233 and parameters: {'lambda_l1': 6.636351489613675, 'lambda_l2': 1.6896363033390012e-06, 'num_leaves': 120, 'feature_fraction': 0.927106545418231, 'bagging_fraction': 0.8997631951438317, 'bagging_freq': 3, 'min_child_samples': 87, 'learning_rate': 0.020264017813497168}. Best is trial 23 with value: 3.542113849338635.\n",
      "[I 2023-12-04 20:38:54,016] Trial 44 finished with value: 3.7010870554959734 and parameters: {'lambda_l1': 0.6904519912544396, 'lambda_l2': 4.749811378002748e-07, 'num_leaves': 74, 'feature_fraction': 0.9811658771743768, 'bagging_fraction': 0.9626196507192568, 'bagging_freq': 6, 'min_child_samples': 84, 'learning_rate': 0.024771697650355605}. Best is trial 23 with value: 3.542113849338635.\n",
      "[I 2023-12-04 20:39:49,983] Trial 45 finished with value: 3.6417125054680834 and parameters: {'lambda_l1': 0.036615279040181095, 'lambda_l2': 2.9623647227174128e-08, 'num_leaves': 139, 'feature_fraction': 0.9624574448001072, 'bagging_fraction': 0.9281093348101022, 'bagging_freq': 5, 'min_child_samples': 76, 'learning_rate': 0.030213306315690892}. Best is trial 23 with value: 3.542113849338635.\n",
      "[I 2023-12-04 20:40:38,871] Trial 46 finished with value: 3.6882397496448074 and parameters: {'lambda_l1': 0.1715224687564439, 'lambda_l2': 6.253510282187773e-07, 'num_leaves': 116, 'feature_fraction': 0.9268230676939511, 'bagging_fraction': 0.8759727670566737, 'bagging_freq': 6, 'min_child_samples': 92, 'learning_rate': 0.08977325893765475}. Best is trial 23 with value: 3.542113849338635.\n",
      "[I 2023-12-04 20:41:22,950] Trial 47 finished with value: 3.7826678296101437 and parameters: {'lambda_l1': 8.490488077633515, 'lambda_l2': 2.0186816463612829e-07, 'num_leaves': 91, 'feature_fraction': 0.8315228533500997, 'bagging_fraction': 0.962473822512118, 'bagging_freq': 4, 'min_child_samples': 100, 'learning_rate': 0.016011542547069036}. Best is trial 23 with value: 3.542113849338635.\n",
      "[I 2023-12-04 20:42:18,314] Trial 48 finished with value: 3.7486181410388304 and parameters: {'lambda_l1': 2.929109584783272, 'lambda_l2': 2.5098653759795692e-06, 'num_leaves': 166, 'feature_fraction': 0.8653477391593419, 'bagging_fraction': 0.9094932386658724, 'bagging_freq': 5, 'min_child_samples': 40, 'learning_rate': 0.051130847782017014}. Best is trial 23 with value: 3.542113849338635.\n",
      "[I 2023-12-04 20:43:05,981] Trial 49 finished with value: 3.6385316116645874 and parameters: {'lambda_l1': 0.06577906009095368, 'lambda_l2': 1.913320631598392e-05, 'num_leaves': 135, 'feature_fraction': 0.8016619066169597, 'bagging_fraction': 0.8549990921938508, 'bagging_freq': 4, 'min_child_samples': 83, 'learning_rate': 0.07188810531109693}. Best is trial 23 with value: 3.542113849338635.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials:  50\n",
      "Best trial:\n",
      "  Value:  3.542113849338635\n",
      "  Params: \n",
      "    lambda_l1: 0.009378943867781906\n",
      "    lambda_l2: 1.6036090134055939e-06\n",
      "    num_leaves: 144\n",
      "    feature_fraction: 0.8952864576742605\n",
      "    bagging_fraction: 0.9284567661492465\n",
      "    bagging_freq: 5\n",
      "    min_child_samples: 49\n",
      "    learning_rate: 0.07958940675014119\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Define the objective function\n",
    "def objective(trial):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(xtrain, ytrain, test_size=0.2)\n",
    "\n",
    "    \n",
    "    param = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'verbose':-1,\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
    "    }\n",
    "\n",
    "    # Train the model\n",
    "    gbm = lgb.LGBMRegressor(**param)\n",
    "    gbm.fit(X_train, y_train, eval_set=[(X_test, y_test)])\n",
    "\n",
    "    # Predict and calculate RMSE\n",
    "    preds = gbm.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    return rmse\n",
    "\n",
    "# Create a study object and optimize the objective function\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)  # You can change the number of trials\n",
    "\n",
    "# Best parameters\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "41832376",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params=trial.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc384ac4",
   "metadata": {},
   "source": [
    "# Train cv lightgbm and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "204e041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling_lgbm_cross_validation(params, X, y, nr_folds=5):\n",
    "    clfs = list()\n",
    "    oof_preds = np.zeros(X.shape[0])\n",
    "\n",
    "    kfolds = StratifiedKFold(n_splits=nr_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    kfolds = KFold(n_splits=nr_folds, shuffle=True, random_state=42)\n",
    "    for n_fold, (trn_idx, val_idx) in enumerate(kfolds.split(X, y)):\n",
    "\n",
    "        X_train, y_train = X.iloc[trn_idx], y.iloc[trn_idx]\n",
    "        X_valid, y_valid = X.iloc[val_idx], y.iloc[val_idx]\n",
    "        \n",
    "        params['early_stopping_rounds']=500\n",
    "        model = lgb.LGBMRegressor(**params)\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_valid, y_valid)],\n",
    "            eval_metric='rmse'\n",
    "        \n",
    "        )\n",
    "\n",
    "        clfs.append(model)\n",
    "        oof_preds[val_idx] = model.predict(X_valid, num_iteration=model.best_iteration_)\n",
    "\n",
    "        del X_train, y_train, X_valid, y_valid\n",
    "        gc.collect()  \n",
    "    score = mean_squared_error(y, oof_preds) ** .5\n",
    "    return clfs, score\n",
    "\n",
    "def predict_cross_validation(test, clfs, ntree_limit=None):\n",
    "    sub_preds = np.zeros(test.shape[0])\n",
    "    for i, model in enumerate(clfs, 1):\n",
    "\n",
    "        num_tree = 10000\n",
    "        if not ntree_limit:\n",
    "            ntree_limit = num_tree\n",
    "\n",
    "        if isinstance(model, lgb.sklearn.LGBMRegressor):\n",
    "            if model.best_iteration_:\n",
    "                num_tree = min(ntree_limit, model.best_iteration_)\n",
    "\n",
    "            test_preds = model.predict(test, raw_score=True, num_iteration=num_tree)\n",
    "\n",
    "        sub_preds += test_preds\n",
    "\n",
    "    sub_preds = sub_preds / len(clfs)\n",
    "    ret = pd.Series(sub_preds, index=test.index)\n",
    "    ret.index.name = test.index.name\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ced01c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dedc95f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.182667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 149533\n",
      "[LightGBM] [Info] Number of data points in the train set: 180076, number of used features: 808\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Info] Start training from score -0.384808\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[33]\tvalid_0's rmse: 3.48336\tvalid_0's l2: 12.1338\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.141071 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 149465\n",
      "[LightGBM] [Info] Number of data points in the train set: 180076, number of used features: 808\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Info] Start training from score -0.378713\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[37]\tvalid_0's rmse: 3.66598\tvalid_0's l2: 13.4394\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.152303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 149598\n",
      "[LightGBM] [Info] Number of data points in the train set: 180076, number of used features: 808\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Info] Start training from score -0.378397\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[83]\tvalid_0's rmse: 3.6159\tvalid_0's l2: 13.0748\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.157376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 149467\n",
      "[LightGBM] [Info] Number of data points in the train set: 180076, number of used features: 808\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Info] Start training from score -0.373590\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[69]\tvalid_0's rmse: 3.78271\tvalid_0's l2: 14.3089\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.163636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 149442\n",
      "[LightGBM] [Info] Number of data points in the train set: 180076, number of used features: 808\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Info] Start training from score -0.377482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[38]\tvalid_0's rmse: 3.70697\tvalid_0's l2: 13.7416\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.163865 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 149396\n",
      "[LightGBM] [Info] Number of data points in the train set: 180077, number of used features: 808\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Info] Start training from score -0.377538\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[69]\tvalid_0's rmse: 3.67837\tvalid_0's l2: 13.5304\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.175516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 149439\n",
      "[LightGBM] [Info] Number of data points in the train set: 180077, number of used features: 808\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Info] Start training from score -0.378584\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[37]\tvalid_0's rmse: 3.81613\tvalid_0's l2: 14.5628\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.181143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 149460\n",
      "[LightGBM] [Info] Number of data points in the train set: 180077, number of used features: 808\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Info] Start training from score -0.378889\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[25]\tvalid_0's rmse: 3.57447\tvalid_0's l2: 12.7769\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.218232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 149536\n",
      "[LightGBM] [Info] Number of data points in the train set: 180077, number of used features: 808\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Info] Start training from score -0.377023\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[75]\tvalid_0's rmse: 3.66078\tvalid_0's l2: 13.4013\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.185547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 149450\n",
      "[LightGBM] [Info] Number of data points in the train set: 180077, number of used features: 808\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] early_stopping_round is set=500, early_stopping_rounds=500 will be ignored. Current value: early_stopping_round=500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Start training from score -0.380064\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[36]\tvalid_0's rmse: 3.59979\tvalid_0's l2: 12.9585\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8952864576742605, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8952864576742605\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009378943867781906, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009378943867781906\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6036090134055939e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6036090134055939e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9284567661492465, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9284567661492465\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Run LightGBM with kfold - done in 4077s\n"
     ]
    }
   ],
   "source": [
    "with timer(\"Run LightGBM with kfold\"):\n",
    "    # modeling\n",
    "    nr_folds=10\n",
    "    clfs, score = modeling_lgbm_cross_validation(best_params,\n",
    "                                                    xtrain,\n",
    "                                                    ytrain,\n",
    "                                                    nr_folds\n",
    "                                                    )\n",
    "\n",
    "\n",
    "    pred_test = predict_cross_validation(xtest, clfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed7886a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2a436ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for this model is 3.659622489141572\n"
     ]
    }
   ],
   "source": [
    "print('Score for this model is',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "da800474",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'card_id':test['card_id'].tolist(),'target':pred_test}).to_csv('pred_test_1.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0a1054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
